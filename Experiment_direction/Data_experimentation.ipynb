{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcvf2MTkUMvE",
        "outputId": "c3a94c31-74be-4494-9f7c-1ce4e79f1127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenNMT-py\n",
            "  Downloading OpenNMT_py-2.2.0-py3-none-any.whl (216 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 19.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 19.7 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 81 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 216 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py) (3.13)\n",
            "Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py) (2.8.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py) (1.10.0+cu111)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py) (1.1.4)\n",
            "Collecting torchtext==0.5.0\n",
            "  Downloading torchtext-0.5.0-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting waitress\n",
            "  Downloading waitress-2.1.1-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting configargparse\n",
            "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
            "Collecting pyonmttok<2,>=1.23\n",
            "  Downloading pyonmttok-1.31.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (16.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.6 MB 23.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py) (1.21.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 36.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py) (4.63.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.44.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.37.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.3->OpenNMT-py) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.3->OpenNMT-py) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.3->OpenNMT-py) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py) (3.2.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->OpenNMT-py) (2.0.1)\n",
            "Installing collected packages: sentencepiece, waitress, torchtext, pyonmttok, configargparse, OpenNMT-py\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "Successfully installed OpenNMT-py-2.2.0 configargparse-1.5.3 pyonmttok-1.31.0 sentencepiece-0.1.96 torchtext-0.5.0 waitress-2.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install OpenNMT-py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXPERIMENT DIRECTION 2**\n",
        "\n",
        "How does the amount of available data affect the learning of irregular past tense forms? Is there a threshold in the amount of data, or in the ratio between regular and irregular forms, that hinders the learning process?\n"
      ],
      "metadata": {
        "id": "YzIqvENfkR3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "with open(\"english_merged_copy.txt\",'r') as file:\n",
        "    lines = file.readlines()\n",
        "        \n",
        "with open(\"reg.txt\",'w') as file:\n",
        "    for line in lines:\n",
        "        # find() returns -1 if no match is found\n",
        "        if line.find(\"irreg\") == -1:\n",
        "            file.write(line)\n",
        "\n",
        "with open(\"irreg.txt\",'w') as file:\n",
        "    for line in lines:\n",
        "        if line.find(\"irreg\") != -1:\n",
        "            file.write(line)\n",
        "\n",
        "with open(\"reg.txt\",'r') as file:\n",
        "    lines_reg = file.readlines()\n",
        "\n",
        "with open(\"irreg.txt\",'r') as file:\n",
        "    lines_irreg = file.readlines()\n",
        "\n",
        "def create_dataset(lines_reg, lines_irreg, num_reg, num_irreg):\n",
        "    with open(\"merged.txt\",'w') as file:\n",
        "        for i in range(num_reg):\n",
        "            line_reg = random.choice(lines_reg)\n",
        "            file.write(line_reg)\n",
        "        for i in range(num_irreg):\n",
        "            line_irreg = random.choice(lines_irreg)\n",
        "            file.write(line_irreg)"
      ],
      "metadata": {
        "id": "P3w6GctsK4MS"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_dataset(lines_reg, lines_irreg,1120,140)"
      ],
      "metadata": {
        "id": "G3NA9BVZLAHa"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "KmiholT143FC"
      },
      "outputs": [],
      "source": [
        "#create new set of src,trg,valid\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import codecs\n",
        "import _pickle as cPickle\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "#set up output file\n",
        "fout_src_train = codecs.open('experiment_1/src_train.txt','wb','utf-8')\n",
        "fout_tgt_train = codecs.open('experiment_1/tgt_train.txt','wb','utf-8')\n",
        "fout_src_valid = codecs.open('experiment_1/src_valid.txt','wb','utf-8')\n",
        "fout_tgt_valid = codecs.open('experiment_1/tgt_valid.txt','wb','utf-8')\n",
        "fout_src_test = codecs.open('experiment_1/src_test.txt','wb','utf-8')\n",
        "fout_tgt_test = codecs.open('experiment_1/tgt_test.txt','wb','utf-8')\n",
        "\n",
        "#read in  data\n",
        "fin = codecs.open('merged.txt','rb','utf-8')\n",
        "\n",
        "sources = []\n",
        "targets = []\n",
        "\n",
        "for line in fin:\n",
        "\tparts = line.strip().split()\n",
        "\tlemma = parts[2]\n",
        "\tform = parts[3]\n",
        "\tsources.append(' '.join(lemma))\n",
        "\ttargets.append(' '.join(form))\n",
        "fin.close()\n",
        "\n",
        "pairs = list(zip(sources,targets))\n",
        "random.shuffle(pairs)\n",
        "\n",
        "#split into train and test\n",
        "train = pairs[:int(.8*len(pairs))]\n",
        "valid = pairs[int(.8*len(pairs)):int(.9*len(pairs))]\n",
        "test = pairs[int(.9*len(pairs)):]\n",
        "\n",
        "#write the outputs\n",
        "for s,t in train:\n",
        "\tfout_src_train.write(s + '\\n')\n",
        "\tfout_tgt_train.write(t + '\\n')\n",
        "\n",
        "for s,t in valid:\n",
        "\tfout_src_valid.write(s + '\\n')\n",
        "\tfout_tgt_valid.write(t + '\\n')\n",
        "\n",
        "for s,t in test:\n",
        "\tfout_src_test.write(s + '\\n')\n",
        "\tfout_tgt_test.write(t + '\\n')\n",
        "\n",
        "\n",
        "\n",
        "fout_src_train.close()\n",
        "fout_tgt_train.close()\n",
        "fout_src_valid.close()\n",
        "fout_tgt_valid.close()\n",
        "fout_src_test.close()\n",
        "fout_tgt_test.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "gs335CmOUu2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5be1e7-7a7f-48bc-b0f9-18dad2ebf299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2022-03-28 14:40:06,637 INFO] Counter vocab from 10000 samples.\n",
            "[2022-03-28 14:40:06,637 INFO] Build vocab on 10000 transformed examples/corpus.\n",
            "[2022-03-28 14:40:06,653 INFO] corpus_1's transforms: TransformPipe()\n",
            "[2022-03-28 14:40:06,757 INFO] Counters src:38\n",
            "[2022-03-28 14:40:06,757 INFO] Counters tgt:38\n"
          ]
        }
      ],
      "source": [
        "!onmt_build_vocab -config config-exp1.yaml -n_sample 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "hmXiFLeNU6wW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a0cd63-53a3-4b0c-b23f-079b74dbecc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-03-28 14:40:12,760 INFO] Missing transforms field for corpus_1 data, set to default: [].\n",
            "[2022-03-28 14:40:12,760 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2022-03-28 14:40:12,761 INFO] Missing transforms field for valid data, set to default: [].\n",
            "[2022-03-28 14:40:12,761 INFO] Parsed 2 corpora from -data.\n",
            "[2022-03-28 14:40:12,761 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.\n",
            "[2022-03-28 14:40:12,761 INFO] Loading vocab from text file...\n",
            "[2022-03-28 14:40:12,761 INFO] Loading src vocabulary from experiment_1/run/example.vocab.src\n",
            "[2022-03-28 14:40:12,761 INFO] Loaded src vocab has 38 tokens.\n",
            "[2022-03-28 14:40:12,762 INFO] Loading tgt vocabulary from experiment_1/run/example.vocab.tgt\n",
            "[2022-03-28 14:40:12,762 INFO] Loaded tgt vocab has 38 tokens.\n",
            "[2022-03-28 14:40:12,762 INFO] Building fields with vocab in counters...\n",
            "[2022-03-28 14:40:12,762 INFO]  * tgt vocab size: 42.\n",
            "[2022-03-28 14:40:12,762 INFO]  * src vocab size: 40.\n",
            "[2022-03-28 14:40:12,762 INFO]  * src vocab size = 40\n",
            "[2022-03-28 14:40:12,763 INFO]  * tgt vocab size = 42\n",
            "[2022-03-28 14:40:12,763 INFO] Building model...\n",
            "[2022-03-28 14:40:15,127 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(40, 300, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (rnn): LSTM(300, 50, num_layers=2, dropout=0.3, bidirectional=True)\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(42, 300, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): StackedLSTM(\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): LSTMCell(400, 100)\n",
            "        (1): LSTMCell(100, 100)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=100, out_features=100, bias=False)\n",
            "      (linear_out): Linear(in_features=200, out_features=100, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=100, out_features=42, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax(dim=-1)\n",
            "  )\n",
            ")\n",
            "[2022-03-28 14:40:15,128 INFO] encoder: 213600\n",
            "[2022-03-28 14:40:15,128 INFO] decoder: 328442\n",
            "[2022-03-28 14:40:15,128 INFO] * number of parameters: 542042\n",
            "[2022-03-28 14:40:15,129 INFO] Starting training on GPU: [0]\n",
            "[2022-03-28 14:40:15,129 INFO] Start training loop and validate every 500 steps...\n",
            "[2022-03-28 14:40:15,129 INFO] corpus_1's transforms: TransformPipe()\n",
            "[2022-03-28 14:40:15,129 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2022-03-28 14:40:15,133 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2022-03-28 14:40:15,138 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2022-03-28 14:40:16,828 INFO] Step 50/ 1000; acc:  13.12; ppl: 24.15; xent: 3.18; lr: 1.00000; 3781/4917 tok/s;      2 sec\n",
            "[2022-03-28 14:40:18,429 INFO] Step 100/ 1000; acc:  15.24; ppl: 21.24; xent: 3.06; lr: 1.00000; 3734/4982 tok/s;      3 sec\n",
            "[2022-03-28 14:40:18,548 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2022-03-28 14:40:18,552 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2022-03-28 14:40:20,073 INFO] Step 150/ 1000; acc:  17.13; ppl: 18.06; xent: 2.89; lr: 1.00000; 3950/5137 tok/s;      5 sec\n",
            "[2022-03-28 14:40:21,628 INFO] Step 200/ 1000; acc:  28.93; ppl: 13.11; xent: 2.57; lr: 1.00000; 3796/5051 tok/s;      6 sec\n",
            "[2022-03-28 14:40:21,848 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2022-03-28 14:40:21,852 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2022-03-28 14:40:23,370 INFO] Step 250/ 1000; acc:  36.45; ppl:  9.38; xent: 2.24; lr: 1.00000; 3787/4930 tok/s;      8 sec\n",
            "[2022-03-28 14:40:24,880 INFO] Step 300/ 1000; acc:  44.39; ppl:  6.51; xent: 1.87; lr: 1.00000; 3843/5120 tok/s;     10 sec\n",
            "[2022-03-28 14:40:25,227 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2022-03-28 14:40:25,232 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2022-03-28 14:40:26,634 INFO] Step 350/ 1000; acc:  51.13; ppl:  5.25; xent: 1.66; lr: 1.00000; 3823/4965 tok/s;     12 sec\n",
            "[2022-03-28 14:40:28,171 INFO] Step 400/ 1000; acc:  63.64; ppl:  3.66; xent: 1.30; lr: 1.00000; 3804/5088 tok/s;     13 sec\n",
            "[2022-03-28 14:40:28,622 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2022-03-28 14:40:28,626 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 11\n",
            "[2022-03-28 14:40:29,954 INFO] Step 450/ 1000; acc:  72.67; ppl:  2.86; xent: 1.05; lr: 1.00000; 3738/4860 tok/s;     15 sec\n",
            "[2022-03-28 14:40:31,498 INFO] Step 500/ 1000; acc:  83.99; ppl:  2.03; xent: 0.71; lr: 1.00000; 3730/4947 tok/s;     16 sec\n",
            "[2022-03-28 14:40:31,498 INFO] valid's transforms: TransformPipe()\n",
            "[2022-03-28 14:40:31,571 INFO] Validation perplexity: 1.88352\n",
            "[2022-03-28 14:40:31,571 INFO] Validation accuracy: 87.5129\n",
            "[2022-03-28 14:40:31,572 INFO] Saving checkpoint experiment_1/run/model_step_500.pt\n",
            "[2022-03-28 14:40:32,151 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 12\n",
            "[2022-03-28 14:40:32,156 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 13\n",
            "[2022-03-28 14:40:33,351 INFO] Step 550/ 1000; acc:  88.19; ppl:  1.73; xent: 0.55; lr: 1.00000; 3640/4725 tok/s;     18 sec\n",
            "[2022-03-28 14:40:34,891 INFO] Step 600/ 1000; acc:  92.10; ppl:  1.48; xent: 0.39; lr: 1.00000; 3727/4957 tok/s;     20 sec\n",
            "[2022-03-28 14:40:35,522 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 14\n",
            "[2022-03-28 14:40:35,526 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 15\n",
            "[2022-03-28 14:40:36,647 INFO] Step 650/ 1000; acc:  93.32; ppl:  1.37; xent: 0.31; lr: 1.00000; 3788/4927 tok/s;     22 sec\n",
            "[2022-03-28 14:40:38,175 INFO] Step 700/ 1000; acc:  94.33; ppl:  1.33; xent: 0.28; lr: 1.00000; 3857/5092 tok/s;     23 sec\n",
            "[2022-03-28 14:40:38,902 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 16\n",
            "[2022-03-28 14:40:38,906 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 17\n",
            "[2022-03-28 14:40:39,934 INFO] Step 750/ 1000; acc:  95.25; ppl:  1.25; xent: 0.22; lr: 1.00000; 3760/4906 tok/s;     25 sec\n",
            "[2022-03-28 14:40:41,476 INFO] Step 800/ 1000; acc:  95.84; ppl:  1.23; xent: 0.21; lr: 1.00000; 3867/5101 tok/s;     26 sec\n",
            "[2022-03-28 14:40:42,325 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 18\n",
            "[2022-03-28 14:40:42,331 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 19\n",
            "[2022-03-28 14:40:43,238 INFO] Step 850/ 1000; acc:  96.56; ppl:  1.18; xent: 0.17; lr: 1.00000; 3654/4816 tok/s;     28 sec\n",
            "[2022-03-28 14:40:44,800 INFO] Step 900/ 1000; acc:  96.60; ppl:  1.18; xent: 0.16; lr: 1.00000; 3885/5090 tok/s;     30 sec\n",
            "[2022-03-28 14:40:45,729 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 20\n",
            "[2022-03-28 14:40:45,734 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 21\n",
            "[2022-03-28 14:40:46,538 INFO] Step 950/ 1000; acc:  96.96; ppl:  1.15; xent: 0.14; lr: 1.00000; 3766/4935 tok/s;     31 sec\n",
            "[2022-03-28 14:40:48,104 INFO] Step 1000/ 1000; acc:  97.22; ppl:  1.14; xent: 0.13; lr: 1.00000; 3792/5006 tok/s;     33 sec\n",
            "[2022-03-28 14:40:48,172 INFO] Validation perplexity: 1.28571\n",
            "[2022-03-28 14:40:48,172 INFO] Validation accuracy: 95.0464\n",
            "[2022-03-28 14:40:48,173 INFO] Saving checkpoint experiment_1/run/model_step_1000.pt\n"
          ]
        }
      ],
      "source": [
        "!onmt_train -config config-exp1.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "YFGf8PahWtdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e787e2f9-ff75-4afd-f122-46cdcb7ad1d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-03-28 14:42:26,909 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-03-28 14:42:27,010 INFO] \n",
            "SENT 1: ['r', '&', 'v', 'I', 'S']\n",
            "PRED 1: r & v I S t\n",
            "PRED SCORE: -0.0518\n",
            "\n",
            "[2022-03-28 14:42:27,010 INFO] \n",
            "SENT 2: ['r', 'i', ':', 'g', '3', ':', 'd', 'Z', 'I', 't', 'e', 'I', 't']\n",
            "PRED 2: r i : g 3 : d Z I t e I t I d\n",
            "PRED SCORE: -0.7815\n",
            "\n",
            "[2022-03-28 14:42:27,011 INFO] \n",
            "SENT 3: ['d', 'i', ':', 'v', '&', 'l', 'j', 'U']\n",
            "PRED 3: d i : v & l j U d\n",
            "PRED SCORE: -0.5528\n",
            "\n",
            "[2022-03-28 14:42:27,011 INFO] \n",
            "SENT 4: ['r', '@', 'z', 'a', 'U', 'n', 'd']\n",
            "PRED 4: r @ z a U n d I d\n",
            "PRED SCORE: -0.1090\n",
            "\n",
            "[2022-03-28 14:42:27,011 INFO] \n",
            "SENT 5: ['k', 'r', 'e', 'I', 'n']\n",
            "PRED 5: k r e I n d\n",
            "PRED SCORE: -0.0393\n",
            "\n",
            "[2022-03-28 14:42:27,011 INFO] \n",
            "SENT 6: ['p', 'O', ':', 't', 'r', 'e', 'I']\n",
            "PRED 6: p O : t r e I d\n",
            "PRED SCORE: -0.1883\n",
            "\n",
            "[2022-03-28 14:42:27,012 INFO] \n",
            "SENT 7: ['s', 'n', 'I', '@', 'r', '*']\n",
            "PRED 7: s n I @ d\n",
            "PRED SCORE: -0.1100\n",
            "\n",
            "[2022-03-28 14:42:27,012 INFO] \n",
            "SENT 8: ['r', 'I', 'd', 'V', 'b', 'l', ',']\n",
            "PRED 8: r I d V b l , d\n",
            "PRED SCORE: -0.0733\n",
            "\n",
            "[2022-03-28 14:42:27,012 INFO] \n",
            "SENT 9: ['S', 'e', 'I', 'p']\n",
            "PRED 9: S e I p t\n",
            "PRED SCORE: -0.0474\n",
            "\n",
            "[2022-03-28 14:42:27,013 INFO] \n",
            "SENT 10: ['S', 'O', ':', 'r', '*']\n",
            "PRED 10: S O : d\n",
            "PRED SCORE: -0.0357\n",
            "\n",
            "[2022-03-28 14:42:27,013 INFO] \n",
            "SENT 11: ['O', ':', 'b', 'I', 't']\n",
            "PRED 11: O : b I t I d\n",
            "PRED SCORE: -0.0583\n",
            "\n",
            "[2022-03-28 14:42:27,013 INFO] \n",
            "SENT 12: ['n', 'O', 'm', 'I', 'n', 'e', 'I', 't']\n",
            "PRED 12: n O m I n e I t I d\n",
            "PRED SCORE: -0.0714\n",
            "\n",
            "[2022-03-28 14:42:27,013 INFO] \n",
            "SENT 13: ['r', '@', 'm', 'I', 't']\n",
            "PRED 13: r @ m I t I d\n",
            "PRED SCORE: -0.0348\n",
            "\n",
            "[2022-03-28 14:42:27,013 INFO] \n",
            "SENT 14: ['r', 'V', 'S']\n",
            "PRED 14: r V S t\n",
            "PRED SCORE: -0.1091\n",
            "\n",
            "[2022-03-28 14:42:27,014 INFO] \n",
            "SENT 15: ['g', 'l', 'u', ':']\n",
            "PRED 15: g l u : d\n",
            "PRED SCORE: -0.1119\n",
            "\n",
            "[2022-03-28 14:42:27,014 INFO] \n",
            "SENT 16: ['k', '@', 'U', 't', 'S']\n",
            "PRED 16: k @ U t S t\n",
            "PRED SCORE: -0.0626\n",
            "\n",
            "[2022-03-28 14:42:27,014 INFO] \n",
            "SENT 17: ['b', '3', ':', 'p']\n",
            "PRED 17: b 3 : p t\n",
            "PRED SCORE: -0.0362\n",
            "\n",
            "[2022-03-28 14:42:27,014 INFO] \n",
            "SENT 18: ['b', 'r', 'i', ':', 't', 'S']\n",
            "PRED 18: b r i : t S t\n",
            "PRED SCORE: -0.0820\n",
            "\n",
            "[2022-03-28 14:42:27,014 INFO] \n",
            "SENT 19: ['E', 'n', 'd', 'O', ':', 's']\n",
            "PRED 19: E n d O : s t\n",
            "PRED SCORE: -0.1040\n",
            "\n",
            "[2022-03-28 14:42:27,015 INFO] \n",
            "SENT 20: ['d', 'I', 'z', 'a', 'I', 'n']\n",
            "PRED 20: d I z a I n d\n",
            "PRED SCORE: -0.0731\n",
            "\n",
            "[2022-03-28 14:42:27,015 INFO] \n",
            "SENT 21: ['d', 'I', 's', 'p', 'j', 'u', ':', 't']\n",
            "PRED 21: d I s p j u : t I d\n",
            "PRED SCORE: -0.1518\n",
            "\n",
            "[2022-03-28 14:42:27,015 INFO] \n",
            "SENT 22: ['t', 'E', 's', 't', 'I', 'f', 'a', 'I']\n",
            "PRED 22: t E s t I f a I d\n",
            "PRED SCORE: -0.0873\n",
            "\n",
            "[2022-03-28 14:42:27,015 INFO] \n",
            "SENT 23: ['a', 'U', 't', 'l', 'A', ':', 's', 't']\n",
            "PRED 23: a U t l A : s t I d\n",
            "PRED SCORE: -0.0829\n",
            "\n",
            "[2022-03-28 14:42:27,016 INFO] \n",
            "SENT 24: ['d', 'Z', 'V', 'm', 'b', 'l', ',']\n",
            "PRED 24: d Z V m b l , d\n",
            "PRED SCORE: -0.2286\n",
            "\n",
            "[2022-03-28 14:42:27,016 INFO] \n",
            "SENT 25: ['@', 'w', 'e', 'I', 'k']\n",
            "PRED 25: @ w e I k t\n",
            "PRED SCORE: -0.1054\n",
            "\n",
            "[2022-03-28 14:42:27,016 INFO] \n",
            "SENT 26: ['h', 'w', 'I', 's', 'l', ',']\n",
            "PRED 26: h w I s l , d\n",
            "PRED SCORE: -0.0403\n",
            "\n",
            "[2022-03-28 14:42:27,016 INFO] \n",
            "SENT 27: ['p', 'r', 'E', 'f', '@', 's']\n",
            "PRED 27: p r E f @ s t\n",
            "PRED SCORE: -0.0491\n",
            "\n",
            "[2022-03-28 14:42:27,016 INFO] \n",
            "SENT 28: ['f', 'l', 'E', 'k']\n",
            "PRED 28: f l E k t\n",
            "PRED SCORE: -0.0487\n",
            "\n",
            "[2022-03-28 14:42:27,017 INFO] \n",
            "SENT 29: ['f', '@', 'm', 'I', 'l', 'I', '@', 'r', 'a', 'I', 'z']\n",
            "PRED 29: f @ m I l I @ r a I z d\n",
            "PRED SCORE: -0.5781\n",
            "\n",
            "[2022-03-28 14:42:27,017 INFO] \n",
            "SENT 30: ['b', 'r', 'a', 'I', 'd', 'l', ',']\n",
            "PRED 30: b r a I d l , d\n",
            "PRED SCORE: -0.1731\n",
            "\n",
            "[2022-03-28 14:42:27,117 INFO] \n",
            "SENT 31: ['f', 'r', 'I', 'n', 'Z']\n",
            "PRED 31: f r I n Z d\n",
            "PRED SCORE: -0.0969\n",
            "\n",
            "[2022-03-28 14:42:27,118 INFO] \n",
            "SENT 32: ['m', 'V', 'f']\n",
            "PRED 32: m V f t\n",
            "PRED SCORE: -0.1504\n",
            "\n",
            "[2022-03-28 14:42:27,118 INFO] \n",
            "SENT 33: ['h', '@', 'l', 'j', 'u', ':', 's', 'I', 'n', 'e', 'I', 't']\n",
            "PRED 33: h @ l j u : s I n e I t I d\n",
            "PRED SCORE: -1.2550\n",
            "\n",
            "[2022-03-28 14:42:27,118 INFO] \n",
            "SENT 34: ['s', 'i', ':', 'm']\n",
            "PRED 34: s i : m d\n",
            "PRED SCORE: -0.0759\n",
            "\n",
            "[2022-03-28 14:42:27,118 INFO] \n",
            "SENT 35: ['k', '@', 'U', 'd']\n",
            "PRED 35: k @ U d I d\n",
            "PRED SCORE: -0.0840\n",
            "\n",
            "[2022-03-28 14:42:27,118 INFO] \n",
            "SENT 36: ['k', '@', 'U', 'p']\n",
            "PRED 36: k @ U p t\n",
            "PRED SCORE: -0.0513\n",
            "\n",
            "[2022-03-28 14:42:27,119 INFO] \n",
            "SENT 37: ['l', 'i', ':', 'v', '@', 'r', '*']\n",
            "PRED 37: l i : v @ d\n",
            "PRED SCORE: -0.0858\n",
            "\n",
            "[2022-03-28 14:42:27,119 INFO] \n",
            "SENT 38: ['r', 'i', ':', 'd', 'I', 's', 't', 'r', 'I', 'b', 'j', 'u', ':', 't']\n",
            "PRED 38: r i : d I s t r u : b u : t I d\n",
            "PRED SCORE: -2.2119\n",
            "\n",
            "[2022-03-28 14:42:27,119 INFO] \n",
            "SENT 39: ['r', 'I', 'O', ':', 'g', 'n', ',', 'a', 'I', 'z']\n",
            "PRED 39: r I N A : g , a I z d\n",
            "PRED SCORE: -2.4745\n",
            "\n",
            "[2022-03-28 14:42:27,119 INFO] \n",
            "SENT 40: ['s', 'n', 'O', ':', 'r', '*']\n",
            "PRED 40: s n O : d\n",
            "PRED SCORE: -0.0856\n",
            "\n",
            "[2022-03-28 14:42:27,120 INFO] \n",
            "SENT 41: ['m', 'u', ':', 't', 'S']\n",
            "PRED 41: m u : t S t\n",
            "PRED SCORE: -0.1258\n",
            "\n",
            "[2022-03-28 14:42:27,120 INFO] \n",
            "SENT 42: ['s', 't', 'E', 'm']\n",
            "PRED 42: s t E m d\n",
            "PRED SCORE: -0.0791\n",
            "\n",
            "[2022-03-28 14:42:27,120 INFO] \n",
            "SENT 43: ['k', '@', 'm', 'I', 't']\n",
            "PRED 43: k @ m I t I d\n",
            "PRED SCORE: -0.0357\n",
            "\n",
            "[2022-03-28 14:42:27,120 INFO] \n",
            "SENT 44: ['l', 'O', 'g']\n",
            "PRED 44: l O g d\n",
            "PRED SCORE: -0.0440\n",
            "\n",
            "[2022-03-28 14:42:27,120 INFO] \n",
            "SENT 45: ['S', 'I', 'f', 't']\n",
            "PRED 45: S I f t I d\n",
            "PRED SCORE: -0.1184\n",
            "\n",
            "[2022-03-28 14:42:27,121 INFO] \n",
            "SENT 46: ['b', '&', 'k', 's', 'l', 'a', 'I', 'd']\n",
            "PRED 46: b & k s l a I d I d\n",
            "PRED SCORE: -0.0769\n",
            "\n",
            "[2022-03-28 14:42:27,121 INFO] \n",
            "SENT 47: ['@', 's', 't', 'O', 'n', 'I', 'S']\n",
            "PRED 47: @ s t O n I S t\n",
            "PRED SCORE: -0.0650\n",
            "\n",
            "[2022-03-28 14:42:27,121 INFO] \n",
            "SENT 48: ['f', 'O', ':', 'S', '&', 'd', '@', 'U']\n",
            "PRED 48: f O : S & d @ U d\n",
            "PRED SCORE: -0.3400\n",
            "\n",
            "[2022-03-28 14:42:27,121 INFO] \n",
            "SENT 49: ['s', 't', 'I', 'N']\n",
            "PRED 49: s t & N\n",
            "PRED SCORE: -1.4043\n",
            "\n",
            "[2022-03-28 14:42:27,122 INFO] \n",
            "SENT 50: ['@', 'n', 'O', 'I', 'n', 't']\n",
            "PRED 50: @ n O I n t I d\n",
            "PRED SCORE: -0.0681\n",
            "\n",
            "[2022-03-28 14:42:27,122 INFO] \n",
            "SENT 51: ['s', 't', 'O', 'p']\n",
            "PRED 51: s t O p t\n",
            "PRED SCORE: -0.0239\n",
            "\n",
            "[2022-03-28 14:42:27,122 INFO] \n",
            "SENT 52: ['s', 'n', 'V', 'f', 'l', ',']\n",
            "PRED 52: s n V f l , d\n",
            "PRED SCORE: -0.0627\n",
            "\n",
            "[2022-03-28 14:42:27,122 INFO] \n",
            "SENT 53: ['s', 'p', '3', ':', 't']\n",
            "PRED 53: s p 3 : t I d\n",
            "PRED SCORE: -0.0342\n",
            "\n",
            "[2022-03-28 14:42:27,122 INFO] \n",
            "SENT 54: ['d', 'I', 's', 'p', 'U', 'z', 'E', 's']\n",
            "PRED 54: d I s p U z E s t\n",
            "PRED SCORE: -0.4005\n",
            "\n",
            "[2022-03-28 14:42:27,123 INFO] \n",
            "SENT 55: ['d', 'I', 'g']\n",
            "PRED 55: d I g d\n",
            "PRED SCORE: -0.3003\n",
            "\n",
            "[2022-03-28 14:42:27,123 INFO] \n",
            "SENT 56: ['s', 'k', 'w', 'i', ':', 'z']\n",
            "PRED 56: s k w i : z d\n",
            "PRED SCORE: -0.1503\n",
            "\n",
            "[2022-03-28 14:42:27,123 INFO] \n",
            "SENT 57: ['k', '@', 'v', 'O', ':', 't']\n",
            "PRED 57: k @ v O : t I d\n",
            "PRED SCORE: -0.0850\n",
            "\n",
            "[2022-03-28 14:42:27,123 INFO] \n",
            "SENT 58: ['s', 'k', 'e', 'I', 'l']\n",
            "PRED 58: s k e I l d\n",
            "PRED SCORE: -0.0298\n",
            "\n",
            "[2022-03-28 14:42:27,123 INFO] \n",
            "SENT 59: ['s', 'k', 'r', '&', 'b', 'l', ',']\n",
            "PRED 59: s k r & b l , d\n",
            "PRED SCORE: -0.0264\n",
            "\n",
            "[2022-03-28 14:42:27,124 INFO] \n",
            "SENT 60: ['h', 'O', 'r', 'I', 'f', 'a', 'I']\n",
            "PRED 60: h O r I f a I d\n",
            "PRED SCORE: -0.0887\n",
            "\n",
            "[2022-03-28 14:42:27,220 INFO] \n",
            "SENT 61: ['w', 'O', 'n', 'd', '@', 'r', '*']\n",
            "PRED 61: w O n d @ d\n",
            "PRED SCORE: -0.0589\n",
            "\n",
            "[2022-03-28 14:42:27,220 INFO] \n",
            "SENT 62: ['I', 'm', 'p', '&', 'k', 't']\n",
            "PRED 62: I m p & k t I d\n",
            "PRED SCORE: -0.0284\n",
            "\n",
            "[2022-03-28 14:42:27,220 INFO] \n",
            "SENT 63: ['s', 'E', 'l']\n",
            "PRED 63: s E l d\n",
            "PRED SCORE: -0.3922\n",
            "\n",
            "[2022-03-28 14:42:27,220 INFO] \n",
            "SENT 64: ['p', 'r', 'a', 'I', 'm']\n",
            "PRED 64: p r a I m d\n",
            "PRED SCORE: -0.2893\n",
            "\n",
            "[2022-03-28 14:42:27,221 INFO] \n",
            "SENT 65: ['b', 'V', 'k']\n",
            "PRED 65: b V k t\n",
            "PRED SCORE: -0.1067\n",
            "\n",
            "[2022-03-28 14:42:27,221 INFO] \n",
            "SENT 66: ['@', 'm', '&', 'l', 'g', '@', 'm', 'e', 'I', 't']\n",
            "PRED 66: @ m & l w @ m e I t I d\n",
            "PRED SCORE: -1.0142\n",
            "\n",
            "[2022-03-28 14:42:27,221 INFO] \n",
            "SENT 67: ['s', 't', 'I', 'l']\n",
            "PRED 67: s t I l d\n",
            "PRED SCORE: -0.3279\n",
            "\n",
            "[2022-03-28 14:42:27,221 INFO] \n",
            "SENT 68: ['S', '&', 'm', 'b', 'l', ',']\n",
            "PRED 68: S & m b l , d\n",
            "PRED SCORE: -0.0401\n",
            "\n",
            "[2022-03-28 14:42:27,221 INFO] \n",
            "SENT 69: ['s', 'V', 'k']\n",
            "PRED 69: s V k t\n",
            "PRED SCORE: -0.1211\n",
            "\n",
            "[2022-03-28 14:42:27,222 INFO] \n",
            "SENT 70: ['@', 'k', 'r', 'u', ':']\n",
            "PRED 70: @ k r u : d\n",
            "PRED SCORE: -0.2327\n",
            "\n",
            "[2022-03-28 14:42:27,222 INFO] \n",
            "SENT 71: ['m', 'I', 's', 'k', '&', 'r', 'I']\n",
            "PRED 71: m I s k & r I d\n",
            "PRED SCORE: -0.0652\n",
            "\n",
            "[2022-03-28 14:42:27,222 INFO] \n",
            "SENT 72: ['a', 'I', 's']\n",
            "PRED 72: a I s t\n",
            "PRED SCORE: -0.0328\n",
            "\n",
            "[2022-03-28 14:42:27,222 INFO] \n",
            "SENT 73: ['k', 'u', ':']\n",
            "PRED 73: k u : d\n",
            "PRED SCORE: -0.1498\n",
            "\n",
            "[2022-03-28 14:42:27,222 INFO] \n",
            "SENT 74: ['k', 'V', 'f']\n",
            "PRED 74: k V f t\n",
            "PRED SCORE: -0.2363\n",
            "\n",
            "[2022-03-28 14:42:27,223 INFO] \n",
            "SENT 75: ['m', 'I', 's', 'p', 'l', 'e', 'I', 's']\n",
            "PRED 75: m I s p l e I s t\n",
            "PRED SCORE: -0.0687\n",
            "\n",
            "[2022-03-28 14:42:27,223 INFO] \n",
            "SENT 76: ['p', 'O', 's', 't', 'j', 'U', 'l', 'e', 'I', 't']\n",
            "PRED 76: p O s t j U l e I t I d\n",
            "PRED SCORE: -0.1789\n",
            "\n",
            "[2022-03-28 14:42:27,223 INFO] \n",
            "SENT 77: ['b', 'V', 's', 'l', ',']\n",
            "PRED 77: b V s l , d\n",
            "PRED SCORE: -0.0289\n",
            "\n",
            "[2022-03-28 14:42:27,223 INFO] \n",
            "SENT 78: ['V', 'n', 'd', '@', 'p', 'e', 'I']\n",
            "PRED 78: V n d @ p e I d\n",
            "PRED SCORE: -0.1325\n",
            "\n",
            "[2022-03-28 14:42:27,224 INFO] \n",
            "SENT 79: ['@', 'm', '&', 'l', 'g', '@', 'm', 'e', 'I', 't']\n",
            "PRED 79: @ m & l w @ m e I t I d\n",
            "PRED SCORE: -1.0142\n",
            "\n",
            "[2022-03-28 14:42:27,224 INFO] \n",
            "SENT 80: ['h', 'A', ':', 'v']\n",
            "PRED 80: h A : v d\n",
            "PRED SCORE: -0.0586\n",
            "\n",
            "[2022-03-28 14:42:27,224 INFO] \n",
            "SENT 81: ['t', 'r', 'I', 'k', 'l', ',']\n",
            "PRED 81: t r I k l , d\n",
            "PRED SCORE: -0.0343\n",
            "\n",
            "[2022-03-28 14:42:27,224 INFO] \n",
            "SENT 82: ['V', 'p', 'r', 'u', ':', 't']\n",
            "PRED 82: V p r u : t I d\n",
            "PRED SCORE: -0.1062\n",
            "\n",
            "[2022-03-28 14:42:27,224 INFO] \n",
            "SENT 83: ['w', 'a', 'I', 'p']\n",
            "PRED 83: w a I p t\n",
            "PRED SCORE: -0.0640\n",
            "\n",
            "[2022-03-28 14:42:27,225 INFO] \n",
            "SENT 84: ['s', 'V', 'p']\n",
            "PRED 84: s V p t\n",
            "PRED SCORE: -0.0539\n",
            "\n",
            "[2022-03-28 14:42:27,225 INFO] \n",
            "SENT 85: ['l', 'O', 'd', 'Z']\n",
            "PRED 85: l O d Z d\n",
            "PRED SCORE: -0.0290\n",
            "\n",
            "[2022-03-28 14:42:27,225 INFO] \n",
            "SENT 86: ['s', 't', 'V', 'n', 't']\n",
            "PRED 86: s t V n t I d\n",
            "PRED SCORE: -0.0459\n",
            "\n",
            "[2022-03-28 14:42:27,225 INFO] \n",
            "SENT 87: ['s', 'I', 'v']\n",
            "PRED 87: s I v\n",
            "PRED SCORE: -0.6067\n",
            "\n",
            "[2022-03-28 14:42:27,225 INFO] \n",
            "SENT 88: ['s', 'p', 'e', 'I']\n",
            "PRED 88: s p e I d\n",
            "PRED SCORE: -0.1354\n",
            "\n",
            "[2022-03-28 14:42:27,226 INFO] \n",
            "SENT 89: ['t', 'E', 'r', '@', 'r', 'a', 'I', 'z']\n",
            "PRED 89: t E r @ r a I z d\n",
            "PRED SCORE: -0.2925\n",
            "\n",
            "[2022-03-28 14:42:27,226 INFO] \n",
            "SENT 90: ['j', 'u', ':', 'n', 'I', '@', 'n', 'a', 'I', 'z']\n",
            "PRED 90: j u : n I U n a I z d\n",
            "PRED SCORE: -0.9311\n",
            "\n",
            "[2022-03-28 14:42:27,327 INFO] \n",
            "SENT 91: ['E', 's', 't', 'I', 'm', 'e', 'I', 't']\n",
            "PRED 91: E s t I m e I t I d\n",
            "PRED SCORE: -0.0642\n",
            "\n",
            "[2022-03-28 14:42:27,327 INFO] \n",
            "SENT 92: ['s', '&', 'N', 'S', 'n', ',']\n",
            "PRED 92: s & N S n , d\n",
            "PRED SCORE: -0.1163\n",
            "\n",
            "[2022-03-28 14:42:27,327 INFO] \n",
            "SENT 93: ['p', 'e', 'I', 'p', '@', 'r', '*']\n",
            "PRED 93: p e I p @ d\n",
            "PRED SCORE: -0.0419\n",
            "\n",
            "[2022-03-28 14:42:27,328 INFO] \n",
            "SENT 94: ['s', 'm', '&', 'k']\n",
            "PRED 94: s m & k t\n",
            "PRED SCORE: -0.0383\n",
            "\n",
            "[2022-03-28 14:42:27,328 INFO] \n",
            "SENT 95: ['s', 't', 'r', '&', 'p']\n",
            "PRED 95: s t r & p t\n",
            "PRED SCORE: -0.0369\n",
            "\n",
            "[2022-03-28 14:42:27,328 INFO] \n",
            "SENT 96: ['h', 'a', 'I', 't', 'n', ',']\n",
            "PRED 96: h a I t n , d\n",
            "PRED SCORE: -0.0612\n",
            "\n",
            "[2022-03-28 14:42:27,328 INFO] \n",
            "SENT 97: ['b', '&', 'k', 'f', 'a', 'I', '@', 'r', '*']\n",
            "PRED 97: b & k f a I @ d\n",
            "PRED SCORE: -0.1134\n",
            "\n",
            "[2022-03-28 14:42:27,328 INFO] \n",
            "SENT 98: ['d', 'I', 'f', 'e', 'I', 'm']\n",
            "PRED 98: d I f e I m d\n",
            "PRED SCORE: -0.0804\n",
            "\n",
            "[2022-03-28 14:42:27,329 INFO] \n",
            "SENT 99: ['r', 'V', 't']\n",
            "PRED 99: r V t I d\n",
            "PRED SCORE: -0.0936\n",
            "\n",
            "[2022-03-28 14:42:27,329 INFO] \n",
            "SENT 100: ['p', 'r', '@', 'v', 'E', 'n', 't']\n",
            "PRED 100: p r @ v E n t I d\n",
            "PRED SCORE: -0.0534\n",
            "\n",
            "[2022-03-28 14:42:27,329 INFO] \n",
            "SENT 101: ['d', 'i', ':', 'k', '&', 'n', 't']\n",
            "PRED 101: d i : k & n t I d\n",
            "PRED SCORE: -0.1245\n",
            "\n",
            "[2022-03-28 14:42:27,329 INFO] \n",
            "SENT 102: ['h', 'V', 'z', 'b', '@', 'n', 'd']\n",
            "PRED 102: h V z b @ n d I d\n",
            "PRED SCORE: -0.9096\n",
            "\n",
            "[2022-03-28 14:42:27,330 INFO] \n",
            "SENT 103: ['l', '@', 'U', 'p']\n",
            "PRED 103: l @ U p t\n",
            "PRED SCORE: -0.1293\n",
            "\n",
            "[2022-03-28 14:42:27,330 INFO] \n",
            "SENT 104: ['b', 'A', ':', 'k']\n",
            "PRED 104: b A : k t\n",
            "PRED SCORE: -0.0205\n",
            "\n",
            "[2022-03-28 14:42:27,330 INFO] \n",
            "SENT 105: ['m', 'a', 'I', 'n', 'd']\n",
            "PRED 105: m a I n d I d\n",
            "PRED SCORE: -0.1020\n",
            "\n",
            "[2022-03-28 14:42:27,330 INFO] \n",
            "SENT 106: ['p', '3', ':', 'f', '@', 'r', 'e', 'I', 't']\n",
            "PRED 106: p 3 : f @ r e I t I d\n",
            "PRED SCORE: -0.0993\n",
            "\n",
            "[2022-03-28 14:42:27,330 INFO] \n",
            "SENT 107: ['a', 'I', 'd', 'l', ',', 'a', 'I', 'z']\n",
            "PRED 107: a I d l , a I z d\n",
            "PRED SCORE: -0.1596\n",
            "\n",
            "[2022-03-28 14:42:27,331 INFO] \n",
            "SENT 108: ['d', 'E', 's', 't', 'I', 'n']\n",
            "PRED 108: d E s t I n d\n",
            "PRED SCORE: -0.0479\n",
            "\n",
            "[2022-03-28 14:42:27,331 INFO] \n",
            "SENT 109: ['d', 'Z', 'I', 'g', 'l', ',']\n",
            "PRED 109: d Z I g l , d\n",
            "PRED SCORE: -0.1982\n",
            "\n",
            "[2022-03-28 14:42:27,331 INFO] \n",
            "SENT 110: ['b', '@', 'g', 'I', 'n']\n",
            "PRED 110: b @ g I n d\n",
            "PRED SCORE: -0.1248\n",
            "\n",
            "[2022-03-28 14:42:27,331 INFO] \n",
            "SENT 111: ['&', 'b', 's', 't', 'e', 'I', 'n']\n",
            "PRED 111: & b s t e I n d\n",
            "PRED SCORE: -0.1188\n",
            "\n",
            "[2022-03-28 14:42:27,332 INFO] \n",
            "SENT 112: ['s', 'p', 'I', 'r', 'I', 't']\n",
            "PRED 112: s p I r I t I d\n",
            "PRED SCORE: -0.0510\n",
            "\n",
            "[2022-03-28 14:42:27,332 INFO] \n",
            "SENT 113: ['k', 'O', 'n', 'v', '3', ':', 'd', 'Z']\n",
            "PRED 113: k O n v 3 : d Z d\n",
            "PRED SCORE: -0.0835\n",
            "\n",
            "[2022-03-28 14:42:27,332 INFO] \n",
            "SENT 114: ['d', 'I', 'k', 'l', 'E', '@', 'r', '*']\n",
            "PRED 114: d I k l E @ d\n",
            "PRED SCORE: -0.0737\n",
            "\n",
            "[2022-03-28 14:42:27,332 INFO] \n",
            "SENT 115: ['V', 'n', 'd', '@', 'v', '&', 'l', 'j', 'U']\n",
            "PRED 115: V n d @ v & l j U d\n",
            "PRED SCORE: -0.8462\n",
            "\n",
            "[2022-03-28 14:42:27,332 INFO] \n",
            "SENT 116: ['E', 'n', 'k', 'r', '@', 'U', 't', 'S']\n",
            "PRED 116: E n k r U U t S t\n",
            "PRED SCORE: -0.2197\n",
            "\n",
            "[2022-03-28 14:42:27,333 INFO] \n",
            "SENT 117: ['b', 'r', 'e', 'I', 'k']\n",
            "PRED 117: b r e I k t\n",
            "PRED SCORE: -0.1151\n",
            "\n",
            "[2022-03-28 14:42:27,333 INFO] \n",
            "SENT 118: ['V', 'n', 'p', '&', 'k']\n",
            "PRED 118: V n p & k t\n",
            "PRED SCORE: -0.0549\n",
            "\n",
            "[2022-03-28 14:42:27,333 INFO] \n",
            "SENT 119: ['r', 'a', 'I', 'l']\n",
            "PRED 119: r a I l d\n",
            "PRED SCORE: -0.2234\n",
            "\n",
            "[2022-03-28 14:42:27,333 INFO] \n",
            "SENT 120: ['&', 'k', 't', 'I', 'v', 'e', 'I', 't']\n",
            "PRED 120: & k t I v e I t I d\n",
            "PRED SCORE: -0.0604\n",
            "\n",
            "[2022-03-28 14:42:27,372 INFO] \n",
            "SENT 121: ['s', 't', 'I', 'N']\n",
            "PRED 121: s t & N\n",
            "PRED SCORE: -1.4043\n",
            "\n",
            "[2022-03-28 14:42:27,373 INFO] \n",
            "SENT 122: ['s', 'k', 'r', 'I', 'b', 'l', ',']\n",
            "PRED 122: s k r I b l , d\n",
            "PRED SCORE: -0.0416\n",
            "\n",
            "[2022-03-28 14:42:27,373 INFO] \n",
            "SENT 123: ['p', 'r', 'U', 't', 'r', 'u', ':', 'd']\n",
            "PRED 123: p r U t r u : d I d\n",
            "PRED SCORE: -0.1595\n",
            "\n",
            "[2022-03-28 14:42:27,373 INFO] \n",
            "SENT 124: ['k', '@', 'n', 'f', 'r', 'V', 'n', 't']\n",
            "PRED 124: k @ n f E n t I d\n",
            "PRED SCORE: -1.3544\n",
            "\n",
            "[2022-03-28 14:42:27,373 INFO] \n",
            "SENT 125: ['t', '@', 'U', 'n']\n",
            "PRED 125: t @ U n d\n",
            "PRED SCORE: -0.0615\n",
            "\n",
            "[2022-03-28 14:42:27,373 INFO] \n",
            "SENT 126: ['s', 'E', 'l']\n",
            "PRED 126: s E l d\n",
            "PRED SCORE: -0.3922\n",
            "\n",
            "[2022-03-28 14:42:27,374 INFO] PRED AVG SCORE: -0.0325, PRED PPL: 1.0330\n"
          ]
        }
      ],
      "source": [
        "!onmt_translate -model experiment_1/run/model_step_1000.pt -src experiment_1/src_test.txt -output experiment_1/test-decoded.txt -gpu 0 -verbose -beam_size 12"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For experimenting purpose\n",
        "\n",
        "import os\n",
        "os.remove(\"experiment_1/src_train.txt\")\n",
        "os.remove(\"experiment_1/src_test.txt\")\n",
        "os.remove(\"experiment_1/src_valid.txt\")\n",
        "os.remove(\"experiment_1/tgt_test.txt\")\n",
        "os.remove(\"experiment_1/tgt_train.txt\")\n",
        "os.remove(\"experiment_1/tgt_valid.txt\")\n",
        "os.remove(\"experiment_1/run/example.vocab.src\")\n",
        "os.remove(\"experiment_1/run/example.vocab.tgt\")\n",
        "os.remove(\"experiment_1/run/model_step_1000.pt\")\n",
        "os.remove(\"experiment_1/run/model_step_500.pt\")"
      ],
      "metadata": {
        "id": "ZjYesJvlhkl9"
      },
      "execution_count": 167,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NLP_Project4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}